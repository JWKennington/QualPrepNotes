\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%        VECTOR ANALYSIS APPENDIX       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Vector Analysis}
\index{Vector Analysis}
\label{app:vec-analysis}
Here we review various techniques within vector calculus and analysis. 

% Vector Algebra
\section{Vector Algebra}
Vectors, by definition, are members of a vector space. It is therefore prudent to summarize the properties of vector fields. A vector space over a field $K$ is a set $V$ equipped with vector addition $+: V\times V \to V$ and scalar multiplication $*: K\times V \to V$, where $+$ is an additive group and $\cdot$ is distributive over $+$ and the underlying field addition $+_K$. There are two additional structures of note. First, a bilinear form $(\cdot,\cdot): V\times V\to K$ that, when positive definite and nondegenerate, forms the familiar inner product $v\cdot w \to k\in K$. Second, a bilinear operator $\times : V\times V \to V$, called the \textit{cross product}, which gives the vector space an algebra structure.

\subsection{Inner Product}
The vector inner product $\cdot$ takes two vectors and produces a scalar. It can be used to measure the angle between two vectors.
\eqn{\vec{A}\cdot\vec{B}=AB\cos\theta=A_x B_x + A_y B_y + A_z B_z}
The inner product is also used to compute magnitudes or the \textit{norm} of a vector.
\eqn{\norm{\vec{A}}=\sqrt{\vec{A}\cdot\vec{A}}=\sqrt{A_x^2 + A_y^2 + A_z^2}}

\subsection{Outer (Cross) Product}
The cross product takes two vectors and produces a vector whose direction corresponds to the right-hand rule.
\eqn{\vec{A}\times\vec{B} = 
	\wrap{A_y B_z - A_z B_y}\vec{\hat{x}} 
	+ \wrap{A_z B_x - A_x B_z}\vec{\hat{y}}
	+ \wrap{A_z B_x - A_x B_z}\vec{\hat{z}}}
\eqn{\vec{A}\times\vec{B} = 
	\begin{vmatrix}
		\hat{i} & \hat{j} & \hat{k}\\
		A_x & A_y & A_z \\
		B_x & B_y & B_z 
	\end{vmatrix}}

\subsection{Triple Product}
The scalar triple product represents the volume of the parallelepiped generated by $\vec{A}$, $\vec{B}$, and $\vec{C}$.
\eqn{\vec{A}\cdot\wrap{\vec{B}\times\vec{C}} = \begin{vmatrix}
	A_x & A_y & A_z \\
	B_x & B_y & B_z \\
	C_x & C_y & C_z 
\end{vmatrix}}
The vector triple product can be simplified 
\eqn{\vec{A} \times \wrap{\vec{B} \times \vec{C}} = \vec{B}\wrap{\vec{A}\cdot\vec{C}} - \vec{C}\wrap{\vec{A}\cdot\vec{B}}}

% Differential Calculus
\section{Differential Calculus}
\subsection{Gradient}
The gradient of a function $f$, denoted $\vec{\del}f$, is a vector that represents the direction in which $f$ changes the greatest.
\eqn{\vec{\del} = \pd{}{x}\vec{\hat{x}} + \pd{}{y}\vec{\hat{y}} + \pd{}{z}\vec{\hat{z}}}

\subsection{Divergence}
The divergence of a vector field measures how much the vector spreads out (or diverges) from the point in question.
\eqn{\vec{\del}\cdot \vec{v} = \pd{v_x}{x} + \pd{v_y}{y} + \pd{v_z}{z}}

\subsection{Curl}
The curl of a vector field measures how much the vector swirls around the point in question.
\eqn{\vec{\del}\times\vec{v} = \begin{vmatrix}
	\hat{i} & \hat{j} & \hat{k} \\
	\p/\p x & \p / \p y & \p/\p z \\
	v_x & v_y & v_z
\end{vmatrix}}

\subsection{Second Derivatives}
The Laplacian $\del^2$ represents a second-order change in a vector. There are also a few useful identities related to closed and exact differential forms.
\eqn{\del^2\vec{v} = \pd[2]{v_x}{x} + \pd[2]{v_y}{y} + \pd[2]{v_z}{z}}
\eqn{\vec{\del} \times \wrap{\vec{\del}f}=0}
\eqn{\vec{\del}\cdot\wrap{\vec{\del}\times \vec{v}}=0}

% Integral Calculus
\section{Integral Calculus}
\subsection{Fundamental Theorem of Calculus}
\eqn{\int_a^b \wrap{\frac{df}{dx}}dx=f(b) - f(a)}

\subsection{Stokes-Cartan Theorem}
The Stokes-Cartan theorem related the integral of a form over a the boundary of a manifold to the integral of the exterior derivative of the form over the whole manifold. The Divergence theorem and Green's theorem are both instances of the more general stokes theorem.
\eqn{\int_{\p\Omega}\omega=\int_\Omega d\omega}
\eqn{\oint_{\Gamma} \vec{v} \cdot d \vec{\Gamma} = \iint_S\vec{v}\cdot d\vec{S} \where \Gamma = \p S}
\eqn{\oiint_S \vec{v}\cdot d\vec{S}  = \iiint_V \wrap{\vec{\del}\cdot v} dV \where S = \p V}

\subsection{Integration by Parts}
Another useful identity is integration by parts, which can help solve integrals that produce iterative expressions, like integrals of the form $\int x^p e^{-x} dx$.
\eqn{\int_a^b f\wrap{\frac{dg}{dx}}dx = fg \Big\rvert_a^b - \int_a^b g \wrap{\frac{df}{dx}}dx}

% Curvilinear Coordinates
\section{Curvilinear Coordinates}
\subsection{Spherical Coordinates}
We adopt the mathematical convention for spherical coordinates $(r, \theta, \phi)$ whereby $\theta$ is the \textit{azimuthal} angle in the $x$-$y$ plane and $\phi$ is the \textit{polar} angle between the radial vector and the $z$-axis. This has the enormous advantage of sharing $\theta$ with polar coordinates in the $x$-$y$ plane. This can be problematic because Griffiths uses the opposite convention \cite{griffithsIntroductionElectrodynamics2018}.
\eqn{x = r\sin\phi\cos\theta \quad\quad y = r\sin\phi\sin\theta \quad\quad z = r \cos\phi}
\begin{align}
	\vec{\hat{r}} &= \sin\phi\cos\theta\ \vec{\hat{x}} + \sin\phi\sin\theta\ \vec{\hat{y}} + \cos\phi\ \vec{\hat{z}} \\
	\vec{\hat{\theta}} &= \cos\phi\cos\theta\ \vec{\hat{x}} + \cos\phi\sin\theta\ \vec{\hat{y}} - \sin\theta\ \vec{\hat{z}} \\
	\vec{\hat{\phi}} &= - \sin\theta\ \vec{\hat{x}} + \cos\theta\ \vec{\hat{y}}
\end{align}
The Gradient and Laplacian can also be written in spherical coordinates, which are often useful:
\eqn{\del = \pd{}{r}\vec{\hat{r}} + \frac{1}{r \sin \phi}\pd{}{\theta} \vec{\hat{\theta}} + \frac{1}{r}\pd{}{\phi}\vec{\hat{\phi}}}
\eqn{\del^2 = \frac{1}{r^2}\pd{}{r}\wrap{r^2 \pd{}{r}} + \frac{1}{r^2 \sin^2\phi}\pd{{}^2}{\theta^2} + \frac{1}{r \sin \phi}\pd{}{\phi}\wrap{\sin\phi \pd{}{\phi}}}

% Dirac Delta
\section{Dirac Delta}
The \textit{Dirac delta} is the first example of a \textit{functional}, or \textit{distribution}, encountered in a traditional physics undergraduate sequence, and is central to the entire theory of electrodynamics. A common example is given by the divergence of $\vec{v} = \frac{1}{r^2} \vec{\hat{r}}$. A naive computation yields $\del \cdot \vec{v} = 0$, which seems counterintuitive. However, $\vec{v}$ attains an infinite value at $0$, and any integral over a spherical region centered at $0$, we obtain a constant $4\pi$. As we will see, this is a Dirac delta function.
% One-Dimensional Dirac Delta
\subsection{One-Dimensional Dirac Delta}
The one-dimensional Dirac delta function is a function that is infinite at one point, and zero elsewhere, that is integrable to a constant value:
\eqn{\delta(x) = 
	\begin{cases}
		0, & x \neq 0 \\
		\infty, & x = 0
	\end{cases} 
\quad\quad \text{such that}\quad\quad \int_{-\infty}^{\infty}\delta(x)\ dx = 1}
By far the most important fact about the delta function, is that, when paired with a general function $f(x)$, the delta function "selects" the value of $f$ at $x=0$, such that $f(x)\delta(x) = f(0)\delta(x)$. This is useful for simplifying integrals. 
\eqn{\int_{-\infty}^{\infty}f(x)\delta(x)dx = f(0)\int_{-\infty}^{\infty}\delta(x)dx = f(0) \quad \implies \quad \int_{-\infty}^{\infty}f(x)\delta(x - a)dx = f(a)}
% Three-Dimensional Dirac Delta
\subsection{Three-Dimensional Dirac Delta}
We can generalize the delta function to three-dimensional space: $\delta^3(\vec{r})=\delta(x)\delta(y)\delta(z)$. Integrating this function over all space exhibits the same "selection" behavior as in the one-dimensional case:
\eqn{\int_{\infty^3}f(\vec{r})\delta^3(\vec{r} - \vec{a})dx^3 = f(\vec{a})}
We can now restate the divergence of the function $f(\vec{r})=\frac{1}{r^2}\vec{\hat{r}}$ in terms of the delta function. 
\eqn{\boxed{\vec{\del} \cdot \wrap{\frac{\vec{\hat{r}}}{r^2}} = 4\pi \delta^3(\vec{r})}}
This can be used to simplify many integrals appearing in electrodynamics and other three-dimensional cases, such as spherical harmonics. For example:
\eqn{\int_{\mathcal{V}}\wrap{r^2 + 2} \vec{\del}\cdot\wrap{\frac{\vec{\hat{r}}}{r^2}} dV = \int_{\mathcal{V}}\wrap{r^2 + 2} 4\pi \delta^3(\vec{r}) dV = 4\pi \wrap{0 + 2} = 8\pi}


% Vector Fields
\newpage
\section{Vector Fields}
\subsection{Potentials (Closed and Exact Forms)}
Given a differential form $a\in \Omega^p$, it is said to be \textit{closed} if it's exterior derivative is zero, $da=0$, and is said to be \textit{exact} if it is the exterior derivative of another form $b \in \Omega^{p-1}$, $a = db$. In the latter case, $b$ would be called the \textit{potential function} of $a$. Since $d^2=0$, all exact forms are closed. Whether or not closed forms are exact depends on the topology, which is out of scope here. 

In the case of a vector field $\vec{F}$ on $\RThree$, the property of having no curl $\vec{\del} \times \vec{F} = 0$ is equivalent to saying $\vec{F}$ is closed. Consequently, there must exist a scalar potential $V$ such that $\vec{F} = -\del V$. To state it more formally:
\eqn{\vec{\del}\times\vec{F} = 0 \implies \vec{F} = -\del V}

\subsection{The Helmholtz Theorem}
The Helmholtz Theorem states that a vector field $\vec{F}$ is uniquely specified by its divergence $\vec{\del}\cdot \vec{F}$ and its curl $\vec{\del}\times \vec{F}$, assuming the boundary condition $\lim_{r\to \infty} \vec{F}(\vec{r})=0$ is strong enough. If this is the case, then $F$ can be constructed from the divergence and curl:
\eqn{\vec{F} = -\del U + \vec{\del}\times \vec{W} \quad\quad \text{where} \quad\quad
\begin{aligned}
	U(\vec{r}) &= \frac{1}{4\pi}\int \frac{\vec{\del}\cdot \vec{F}}{\norm{\vec{r} - \vec{r}'}} dr'^3 \\
	\ & \ \\
	\vec{W}(\vec{r}) &= \frac{1}{4\pi} \int\frac{\vec{\del}\times \vec{F}}{\norm{\vec{r} - \vec{r}'}}dr'^3 \\
\end{aligned}}


% Substitutions
\section{Substitutions}
%Various integrals can be simplified via substitution techniques. This section details two such substitution methods, both of which have been useful in undergraduate physics.
\subsection{Trigonometric Substitution}
Substituting trigonometric functions for more complicated expressions can simplify an integral. The below cases highlight the most common trig substitutions:
\eqn{\begin{array}{ccc}
	\textbf{Case} & \textbf{Integrand Contains} & \textbf{Substitution} \\
	\text{I}   & a^2 - x^2 & x = a\sin\theta \\
	\text{II}  & a^2 + x^2 & x = a\tan\theta \\
	\text{III} & x^2 - a^2 & x = a\sec\theta \\
\end{array}}

\subsection{Weierstrass Substitution}
The Weierstrass substitution transforms a function that depends on basic trigonometric functions of an angle into a function that depends on algebraic variables. Specifically, the substitution is:
\eqn{t = \tan\wrap{\frac{\theta}{2}} \implies \left\{
\begin{aligned}
	\sin(\theta) &= \frac{2t}{1 + t^2} \\
	\cos(\theta) &= \frac{1 - t^2}{1 + t^2} \\
\end{aligned}\right.}
\eqn{f\wrap{\sin \theta, \cos \theta} \to f\wrap{\frac{2t}{1 + t^2}, \frac{1 - t^2}{1 + t^2}}}

